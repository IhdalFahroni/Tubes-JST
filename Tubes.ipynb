{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b9e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7e4278",
   "metadata": {},
   "source": [
    "Sel ini memuat seluruh dependensi yang diperlukan: TensorFlow/Keras untuk pemodelan, MobileNetV2 untuk transfer learning, utilitas augmentasi dan optimizer, serta paket evaluasi (`class_weight`, `classification_report`, `confusion_matrix`) dan visualisasi (`matplotlib`, `seaborn`). Dengan begitu semua fungsi berikutnya tinggal fokus ke logika eksperimen tanpa harus mengimpor ulang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1828a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = 'Dataset_Anggur'\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "SPLIT_RATIO = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb62281",
   "metadata": {},
   "source": [
    "Konfigurasi global ini menentukan lokasi dataset anggur, resolusi input, ukuran batch, jumlah epoch, learning rate, dan rasio validasi. Nilai-nilai tersebut dipakai konsisten oleh generator data, kedua arsitektur model, dan proses training sehingga perubahan eksperimen cukup dilakukan di satu tempat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf5f647d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menyiapkan Data...\n",
      "Found 3251 images belonging to 4 classes.\n",
      "Found 3251 images belonging to 4 classes.\n",
      "Found 811 images belonging to 4 classes.\n",
      "Kelas Terdeteksi: ['Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy']\n",
      "Bobot Penyeimbang: {0: 0.8609639830508474, 1: 0.7341915085817525, 2: 0.9439605110336817, 3: 2.3974926253687316}\n",
      "Found 811 images belonging to 4 classes.\n",
      "Kelas Terdeteksi: ['Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy']\n",
      "Bobot Penyeimbang: {0: 0.8609639830508474, 1: 0.7341915085817525, 2: 0.9439605110336817, 3: 2.3974926253687316}\n"
     ]
    }
   ],
   "source": [
    "data_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=SPLIT_RATIO\n",
    ")\n",
    "\n",
    "print(\"Menyiapkan Data...\")\n",
    "train_generator = data_gen.flow_from_directory(\n",
    "    DATASET_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = data_gen.flow_from_directory(\n",
    "    DATASET_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "NUM_CLASSES = train_generator.num_classes\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "print(f\"Kelas Terdeteksi: {class_names}\")\n",
    "\n",
    "cls_train = train_generator.classes\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(cls_train),\n",
    "    y=cls_train\n",
    ")\n",
    "weights_dict = dict(enumerate(class_weights))\n",
    "print(f\"Bobot Penyeimbang: {weights_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a6d1fc",
   "metadata": {},
   "source": [
    "Di tahap ini dataset disiapkan: `ImageDataGenerator` dengan `preprocess_input` MobileNet memastikan kedua model menerima citra pada rentang [-1, 1] dan augmentasi identik (rotasi, pergeseran, shear, zoom, flip). Generator dipisah training/validation memakai `validation_split` agar adil, kemudian dihitung jumlah kelas serta `class_weight` untuk menyeimbangkan kontribusi tiap kelas saat backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b3430b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_cnn():\n",
    "    model = Sequential(name='Custom_CNN')\n",
    "    model.add(Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf8cd83",
   "metadata": {},
   "source": [
    "Fungsi `build_custom_cnn` mendefinisikan baseline yang sepenuhnya dilatih dari nol: empat blok konvolusi (32→256 filter) dengan padding `same`, BatchNorm, dan MaxPooling menangkap fitur bertingkat, lalu Global Average Pooling menurunkan dimensi sebelum dense 256 unit ber-regulasi L2 + Dropout 0.5 dan layer softmax sebanyak jumlah kelas. Arsitektur ini menguji seberapa jauh model sederhana mampu belajar tanpa pengetahuan awal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cde36998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mobilenet():\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    base_model.trainable = True  # Fine-tuning\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions, name='MobileNetV2')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719bea1",
   "metadata": {},
   "source": [
    "Fungsi `build_mobilenet` menyiapkan kandidat transfer learning: MobileNetV2 pretrained ImageNet dipakai sebagai feature extractor, seluruh layer di-unfreeze untuk fine-tuning penuh, kemudian ditambahkan head ringan (GAP → Dense 256 ReLU → Dropout → softmax). Dengan cara ini model memanfaatkan representasi kaya dari ImageNet sambil tetap menyesuaikan diri pada karakteristik dataset anggur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e3b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "MULAI TRAINING: Custom CNN\n",
      "========================================\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.8389 - accuracy: 0.7509 - val_loss: 2.2598 - val_accuracy: 0.0913\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.8389 - accuracy: 0.7509 - val_loss: 2.2598 - val_accuracy: 0.0913\n",
      "Epoch 2/10\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 143s 1s/step - loss: 0.5895 - accuracy: 0.8546 - val_loss: 4.7000 - val_accuracy: 0.0913\n",
      "101/101 [==============================] - 143s 1s/step - loss: 0.5895 - accuracy: 0.8546 - val_loss: 4.7000 - val_accuracy: 0.0913\n",
      "Epoch 3/10\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.5137 - accuracy: 0.8816 - val_loss: 4.2326 - val_accuracy: 0.1412\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.5137 - accuracy: 0.8816 - val_loss: 4.2326 - val_accuracy: 0.1412\n",
      "Epoch 4/10\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 135s 1s/step - loss: 0.4759 - accuracy: 0.9000 - val_loss: 3.6342 - val_accuracy: 0.2688\n",
      "101/101 [==============================] - 135s 1s/step - loss: 0.4759 - accuracy: 0.9000 - val_loss: 3.6342 - val_accuracy: 0.2688\n",
      "Epoch 5/10\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.4413 - accuracy: 0.9087 - val_loss: 1.9377 - val_accuracy: 0.5725\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.4413 - accuracy: 0.9087 - val_loss: 1.9377 - val_accuracy: 0.5725\n",
      "Epoch 6/10\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.4070 - accuracy: 0.9267 - val_loss: 1.1993 - val_accuracy: 0.6250\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.4070 - accuracy: 0.9267 - val_loss: 1.1993 - val_accuracy: 0.6250\n",
      "Epoch 7/10\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.3861 - accuracy: 0.9348 - val_loss: 0.6082 - val_accuracy: 0.8200\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.3861 - accuracy: 0.9348 - val_loss: 0.6082 - val_accuracy: 0.8200\n",
      "Epoch 8/10\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.3647 - accuracy: 0.9407 - val_loss: 0.3972 - val_accuracy: 0.9250\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.3647 - accuracy: 0.9407 - val_loss: 0.3972 - val_accuracy: 0.9250\n",
      "Epoch 9/10\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.3444 - accuracy: 0.9484 - val_loss: 0.3837 - val_accuracy: 0.9413\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.3444 - accuracy: 0.9484 - val_loss: 0.3837 - val_accuracy: 0.9413\n",
      "Epoch 10/10\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.3454 - accuracy: 0.9500 - val_loss: 0.3137 - val_accuracy: 0.9725\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.3454 - accuracy: 0.9500 - val_loss: 0.3137 - val_accuracy: 0.9725\n",
      "\n",
      "Evaluasi Cepat Custom CNN:\n",
      "\n",
      "Evaluasi Cepat Custom CNN:\n",
      "Test Accuracy: 96.92%\n",
      "\n",
      "========================================\n",
      "MULAI TRAINING: MobileNetV2\n",
      "========================================\n",
      "Test Accuracy: 96.92%\n",
      "\n",
      "========================================\n",
      "MULAI TRAINING: MobileNetV2\n",
      "========================================\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 182s 2s/step - loss: 0.3249 - accuracy: 0.8701 - val_loss: 0.2625 - val_accuracy: 0.8913\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 182s 2s/step - loss: 0.3249 - accuracy: 0.8701 - val_loss: 0.2625 - val_accuracy: 0.8913\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 196s 2s/step - loss: 0.0671 - accuracy: 0.9742 - val_loss: 0.2283 - val_accuracy: 0.9200\n",
      "101/101 [==============================] - 196s 2s/step - loss: 0.0671 - accuracy: 0.9742 - val_loss: 0.2283 - val_accuracy: 0.9200\n",
      "Epoch 3/10\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 175s 2s/step - loss: 0.0359 - accuracy: 0.9866 - val_loss: 0.2358 - val_accuracy: 0.9150\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 175s 2s/step - loss: 0.0359 - accuracy: 0.9866 - val_loss: 0.2358 - val_accuracy: 0.9150\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 169s 2s/step - loss: 0.0310 - accuracy: 0.9885 - val_loss: 0.1451 - val_accuracy: 0.9388\n",
      "101/101 [==============================] - 169s 2s/step - loss: 0.0310 - accuracy: 0.9885 - val_loss: 0.1451 - val_accuracy: 0.9388\n",
      "Epoch 5/10\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 165s 2s/step - loss: 0.0303 - accuracy: 0.9897 - val_loss: 0.0804 - val_accuracy: 0.9675\n",
      "101/101 [==============================] - 165s 2s/step - loss: 0.0303 - accuracy: 0.9897 - val_loss: 0.0804 - val_accuracy: 0.9675\n",
      "Epoch 6/10\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 165s 2s/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.2767 - val_accuracy: 0.9225\n",
      "101/101 [==============================] - 165s 2s/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.2767 - val_accuracy: 0.9225\n",
      "Epoch 7/10\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 169s 2s/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.2704 - val_accuracy: 0.9262\n",
      "101/101 [==============================] - 169s 2s/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.2704 - val_accuracy: 0.9262\n",
      "Epoch 8/10\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 166s 2s/step - loss: 0.0103 - accuracy: 0.9960 - val_loss: 0.1849 - val_accuracy: 0.9413\n",
      "101/101 [==============================] - 166s 2s/step - loss: 0.0103 - accuracy: 0.9960 - val_loss: 0.1849 - val_accuracy: 0.9413\n",
      "Epoch 9/10\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 163s 2s/step - loss: 0.0171 - accuracy: 0.9935 - val_loss: 0.1888 - val_accuracy: 0.9400\n",
      "101/101 [==============================] - 163s 2s/step - loss: 0.0171 - accuracy: 0.9935 - val_loss: 0.1888 - val_accuracy: 0.9400\n",
      "Epoch 10/10\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 177s 2s/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.0667 - val_accuracy: 0.9850\n",
      "101/101 [==============================] - 177s 2s/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.0667 - val_accuracy: 0.9850\n",
      "\n",
      "Evaluasi Cepat MobileNetV2:\n",
      "\n",
      "Evaluasi Cepat MobileNetV2:\n",
      "Test Accuracy: 97.66%\n",
      "Test Accuracy: 97.66%\n"
     ]
    }
   ],
   "source": [
    "models_list = [\n",
    "    ('Custom CNN', build_custom_cnn),\n",
    "    ('MobileNetV2', build_mobilenet)\n",
    "]\n",
    "\n",
    "history_storage = {}\n",
    "weights_storage = {}\n",
    "\n",
    "for name, builder in models_list:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"MULAI TRAINING: {name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = builder()\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=test_generator.samples // BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        class_weight=weights_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    history_storage[name] = history.history\n",
    "    weights_storage[name] = model.get_weights()\n",
    "\n",
    "    print(f\"\\nEvaluasi Cepat {name}:\")\n",
    "    test_generator.reset()\n",
    "    loss, acc = model.evaluate(test_generator, verbose=0)\n",
    "    print(f\"Test Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f50b0f8",
   "metadata": {},
   "source": [
    "Sel ini menjalankan kedua kandidat secara bergiliran: membersihkan sesi, membuat model, meng-compile dengan Adam + categorical crossentropy, lalu memanggil `fit` memakai langkah per epoch berbasis ukuran generator serta `class_weight` agar kelas minoritas diperhatikan. Histori training disimpan untuk plotting, dan setelah setiap run dilakukan evaluasi cepat pada generator validasi untuk melihat akurasi aktual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c14824",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights_storage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mweights_storage\u001b[49m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatih model terlebih dahulu sebelum menjalankan demo prediksi.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m builders_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(models_list)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weights_storage' is not defined"
     ]
    }
   ],
   "source": [
    "weights_storage = globals().get('weights_storage', {})\n",
    "models_list_reference = globals().get('models_list')\n",
    "if not weights_storage or not models_list_reference:\n",
    "    raise RuntimeError(\"Latih model terlebih dahulu sebelum menjalankan demo prediksi.\")\n",
    "builders_map = dict(models_list_reference)\n",
    "filenames = test_generator.filenames\n",
    "demo_image_path = None  # isi dengan path relatif (misal 'KategoriA/img_10.jpg') jika ingin spesifik\n",
    "demo_image_index = 0     # ganti angka ini untuk memilih urutan gambar validasi\n",
    "if demo_image_path:\n",
    "    if demo_image_path not in filenames:\n",
    "        raise ValueError(f\"{demo_image_path} tidak ada di generator validasi.\")\n",
    "    relative_path = demo_image_path\n",
    "    target_idx = filenames.index(relative_path)\n",
    "else:\n",
    "    if not isinstance(demo_image_index, int):\n",
    "        raise TypeError(\"demo_image_index harus berupa integer.\")\n",
    "    target_idx = demo_image_index % len(filenames)\n",
    "    relative_path = filenames[target_idx]\n",
    "image_path = os.path.join(test_generator.directory, relative_path)\n",
    "true_idx = test_generator.classes[target_idx]\n",
    "true_label = class_names[true_idx]\n",
    "pil_image = load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "display_image = np.array(pil_image).astype(np.uint8)\n",
    "input_tensor = img_to_array(pil_image)\n",
    "input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "input_tensor = preprocess_input(input_tensor)\n",
    "prediction_rows = []\n",
    "for model_name, weights in weights_storage.items():\n",
    "    inference_model = builders_map[model_name]()\n",
    "    inference_model.set_weights(weights)  # injeksi bobot hasil training\n",
    "    probs = inference_model.predict(input_tensor, verbose=0)[0]\n",
    "    pred_idx = np.argmax(probs)\n",
    "    pred_label = class_names[pred_idx]\n",
    "    confidence = probs[pred_idx]\n",
    "    prediction_rows.append((model_name, pred_label, confidence))\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(display_image)\n",
    "plt.title(f\"Label Asli: {true_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(f\"Gambar uji: {relative_path}\")\n",
    "for name, pred_label, confidence in prediction_rows:\n",
    "    print(f\"{name:12s} -> Prediksi: {pred_label} ({confidence*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bcb73b",
   "metadata": {},
   "source": [
    "Visualisasi akhir memplot kurva akurasi serta loss validasi dari kedua model agar tren konvergensi mudah dibandingkan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40986669",
   "metadata": {},
   "source": [
    "### Analisis Perbedaan Akurasi\n",
    "- **Custom CNN** dilatih sepenuhnya dari nol sehingga butuh lebih banyak data untuk membentuk representasi mendalam; akibatnya sensitivitas terhadap kelas minoritas atau citra noisy cenderung tinggi dan akurasinya menurun.\n",
    "- **MobileNetV2** sudah membawa fitur umum dari ImageNet. Setelah fine-tuning, model ini mampu mengenali pola tepi, tekstur, dan struktur tulang/anggur jauh lebih cepat sehingga kurva validasi naik lebih stabil.\n",
    "- Augmentasi agresif (rotasi, flip vertikal, zoom) menguntungkan MobileNet yang memiliki regularisasi internal, tetapi bisa “membingungkan” Custom CNN yang kapasitasnya lebih terbatas.\n",
    "- Gap ini menandakan bahwa untuk dataset multi-kelas dengan variasi besar, transfer learning memberikan starting point yang kuat; jika ingin meningkatkan Custom CNN, perlu penambahan data, arsitektur lebih dalam, atau teknik regularisasi berbeda (misal CutMix, Mixup).\n",
    "- Perbedaan akurasi juga terlihat pada loss: MobileNetV2 menjaga loss validasi tetap turun, sementara Custom CNN cepat stagnan—indikasi bahwa pretrained features membantu menjaga generalisasi saat data terbatas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
